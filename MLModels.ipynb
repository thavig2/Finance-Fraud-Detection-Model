{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24fe26c8-ae2a-407c-8b6a-2894fd1d17f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T23:54:33.077944Z",
     "iopub.status.busy": "2025-03-18T23:54:33.077486Z",
     "iopub.status.idle": "2025-03-18T23:54:33.223587Z",
     "shell.execute_reply": "2025-03-18T23:54:33.222735Z",
     "shell.execute_reply.started": "2025-03-18T23:54:33.077906Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8ae8df48544ecf89f7c62de5bd50c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 3 core(s) on appid:  application_1742332084551_0004\n",
      "<pyspark.sql.session.SparkSession object at 0x7f78f3774700>"
     ]
    }
   ],
   "source": [
    "# First let's create our PySpark instance\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "# May take awhile locally\n",
    "spark = SparkSession.builder.appName(\"FD_ML\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "appid = spark._jsc.sc().applicationId()\n",
    "print(\"You are working with\", cores, \"core(s) on appid: \",appid)\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09d3fc1f-85d5-40c6-9db2-5ec47aa83a03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T23:54:33.224812Z",
     "iopub.status.busy": "2025-03-18T23:54:33.224572Z",
     "iopub.status.idle": "2025-03-18T23:54:33.423432Z",
     "shell.execute_reply": "2025-03-18T23:54:33.420281Z",
     "shell.execute_reply.started": "2025-03-18T23:54:33.224777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87bcf1c921c94da5b3114e2720e80a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Package already installed for current Spark context!\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1742332084551_0004/container_1742332084551_0004_01_000001/pyspark.zip/pyspark/context.py\", line 2614, in install_pypi_package\n",
      "    raise ValueError(\"Package already installed for current Spark context!\")\n",
      "ValueError: Package already installed for current Spark context!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install pandas and numpy in EMR cluster\n",
    "sc.install_pypi_package(\"pandas\")\n",
    "sc.install_pypi_package(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4616564e-02bc-45cd-a64f-76a9bf1da42f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T23:54:33.425112Z",
     "iopub.status.busy": "2025-03-18T23:54:33.424854Z",
     "iopub.status.idle": "2025-03-18T23:54:33.617937Z",
     "shell.execute_reply": "2025-03-18T23:54:33.616767Z",
     "shell.execute_reply.started": "2025-03-18T23:54:33.425073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafd8a87761d45678e6ee9223219e7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"s3://fd-final/fraud_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53cb6f27-02e9-4f20-b8b4-75ddce8d6cbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T23:54:33.624550Z",
     "iopub.status.busy": "2025-03-18T23:54:33.624299Z",
     "iopub.status.idle": "2025-03-18T23:54:34.990141Z",
     "shell.execute_reply": "2025-03-18T23:54:34.985819Z",
     "shell.execute_reply.started": "2025-03-18T23:54:33.624513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0915b9f5c0b45a98dc8b6f9d6f8c4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: integer (nullable = true)\n",
      " |-- scaled_features: vector (nullable = true)\n",
      "\n",
      "+-----+------------------------------------------------------------------------------------------------------------------+\n",
      "|label|scaled_features                                                                                                   |\n",
      "+-----+------------------------------------------------------------------------------------------------------------------+\n",
      "|0    |[0.0013268461796048614,0.75,0.47058823529411764,0.9862637362637363,0.13043478260869565,0.6666666666666666,0.0,0.5]|\n",
      "|0    |[0.011691847066007444,0.25,0.39215686274509803,0.7967032967032968,0.7391304347826086,0.3333333333333333,0.0,0.0]  |\n",
      "|1    |[0.0507353201883113,0.75,0.43137254901960786,0.07967032967032968,0.8695652173913043,0.3333333333333333,1.0,0.5]   |\n",
      "|0    |[0.004581716469360017,1.0,0.3529411764705882,0.1098901098901099,0.08695652173913043,1.0,1.0,1.0]                  |\n",
      "|0    |[0.011393227884255518,1.0,0.6862745098039216,0.2802197802197802,0.9565217391304348,0.3333333333333333,1.0,0.0]    |\n",
      "+-----+------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "path = \"s3a://fd-final/fraud_data/fraud_processed.parquet\"\n",
    "\n",
    "fraud_data_df = spark.read.parquet(path)\n",
    "\n",
    "fraud_data_df.printSchema()\n",
    "fraud_data_df.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fe144fc-3f7c-48dd-bafb-778ff5e7d23f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T23:54:34.993492Z",
     "iopub.status.busy": "2025-03-18T23:54:34.992877Z",
     "iopub.status.idle": "2025-03-18T23:54:35.842815Z",
     "shell.execute_reply": "2025-03-18T23:54:35.842108Z",
     "shell.execute_reply.started": "2025-03-18T23:54:34.993451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15fb3c7af9174970894aaed5c500d7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First - Read in dependencies\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8197e9ef-16a2-4fa5-adf5-d6a2346505f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T23:54:35.844222Z",
     "iopub.status.busy": "2025-03-18T23:54:35.844033Z",
     "iopub.status.idle": "2025-03-18T23:54:35.911581Z",
     "shell.execute_reply": "2025-03-18T23:54:35.910747Z",
     "shell.execute_reply.started": "2025-03-18T23:54:35.844197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197a342c10f44956a80a1017938a72da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93ace5ff-d473-4280-bbf9-491ee5e49c26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T23:54:35.913259Z",
     "iopub.status.busy": "2025-03-18T23:54:35.912772Z",
     "iopub.status.idle": "2025-03-18T23:54:36.160091Z",
     "shell.execute_reply": "2025-03-18T23:54:36.159164Z",
     "shell.execute_reply.started": "2025-03-18T23:54:35.913156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251de4e468be42e4b0737ceb16fbe515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rename `scaled_features` to `features` so that the ML libraries model will be able to understand it as input column = features\n",
    "fraud_data_df = fraud_data_df.withColumnRenamed(\"scaled_features\", \"features\")\n",
    "\n",
    "# Split into train and test splits\n",
    "train, test = fraud_data_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3b13eec-c520-454b-a900-0910296257aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T23:54:36.161868Z",
     "iopub.status.busy": "2025-03-18T23:54:36.161151Z",
     "iopub.status.idle": "2025-03-18T23:54:36.279472Z",
     "shell.execute_reply": "2025-03-18T23:54:36.273119Z",
     "shell.execute_reply.started": "2025-03-18T23:54:36.161829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a7f7b3f1574d03afe0fe8de5bf0b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cd0525b-64b7-42ad-8b82-5bd7d3fb571e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T23:54:36.281286Z",
     "iopub.status.busy": "2025-03-18T23:54:36.280665Z",
     "iopub.status.idle": "2025-03-18T23:56:38.832140Z",
     "shell.execute_reply": "2025-03-18T23:56:38.830728Z",
     "shell.execute_reply.started": "2025-03-18T23:54:36.281234Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ac76cd20cb41c8a9485bcd0d8d9050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in cell_monitor\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in <listcomp>\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "KeyError: 'jobGroup'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [-1.970427840614607]\n",
      "Coefficients: \n",
      "DenseMatrix([[ 3.01864629e+01, -7.06929575e-03, -2.98822835e-02,\n",
      "              -2.26093627e+00, -1.77410818e+00,  1.16370881e-02,\n",
      "              -2.72837998e-03, -1.17584872e-02]])\n",
      "Accuracy: 95.47%\n",
      "AUC LR: 0.5561"
     ]
    }
   ],
   "source": [
    "# load libraries \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Set up evaluation objects\n",
    "Bin_evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")  # AUC evaluation\n",
    "MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")  # Accuracy evaluation\n",
    "\n",
    "# Logistic Regression Model\n",
    "classifier = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Set up parameter grid for hyperparameter tuning\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(classifier.maxIter, [10, 15, 20])\n",
    "             .build())\n",
    "\n",
    "# Set up Cross Validator\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MC_evaluator,\n",
    "                          numFolds=3)  # 3+ is best practice\n",
    "\n",
    "# Train the model\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Collect the best model\n",
    "BestModel = fitModel.bestModel\n",
    "print(\"Intercept: \" + str(BestModel.interceptVector))\n",
    "print(\"Coefficients: \\n\" + str(BestModel.coefficientMatrix))\n",
    "\n",
    "#Logistic Regression Identifer for ML Models \n",
    "LR_BestModel = BestModel\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = fitModel.transform(test)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = MC_evaluator.evaluate(predictions) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Compute AUC for binary classification\n",
    "auc = Bin_evaluator.evaluate(predictions)\n",
    "print(f\"AUC LR: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6206d5fa-416a-4acf-b06b-91bcc9ceec16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T23:56:38.833902Z",
     "iopub.status.busy": "2025-03-18T23:56:38.833422Z",
     "iopub.status.idle": "2025-03-18T23:56:52.157944Z",
     "shell.execute_reply": "2025-03-18T23:56:52.157276Z",
     "shell.execute_reply.started": "2025-03-18T23:56:38.833862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62e8ae3e76747f58848a647c4f29d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in cell_monitor\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in <listcomp>\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "KeyError: 'jobGroup'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+--------------------+\n",
      "|summary|              label|          prediction|\n",
      "+-------+-------------------+--------------------+\n",
      "|  count|            1046711|             1046711|\n",
      "|   mean|0.05016284342096338|0.006606408072524317|\n",
      "| stddev|0.21828096133462427| 0.08101092342888183|\n",
      "|    min|                0.0|                 0.0|\n",
      "|    max|                1.0|                 1.0|\n",
      "+-------+-------------------+--------------------+\n",
      "\n",
      " \n",
      "objectiveHistory: (scaled loss + regularization) at each iteration\n",
      "0.19899444701205124\n",
      "0.17256204802835995\n",
      "0.16720069933150394\n",
      "0.1657257179246831\n",
      "0.16508556860487592\n",
      "0.16502899971421386\n",
      "0.16502661147334755\n",
      "0.1650265083167095\n",
      "0.16502650486233728\n",
      "0.16502650485356046\n",
      " \n",
      "False positive rate by label:\n",
      "label 0: 0.8850036186340609\n",
      "label 1: 0.0008821118381018\n",
      " \n",
      "True positive rate by label:\n",
      "label 0: 0.9991178881618982\n",
      "label 1: 0.11499638136593913\n",
      " \n",
      "Precision by label:\n",
      "label 0: 0.9553104647450077\n",
      "label 1: 0.8731742588575561\n",
      " \n",
      "Recall by label:\n",
      "label 0: 0.9991178881618982\n",
      "label 1: 0.11499638136593913\n",
      " \n",
      "F-measure by label:\n",
      "label 0: 0.9767232169502374\n",
      "label 1: 0.20322781508221\n",
      " \n",
      "Accuracy: 0.9547678394513863\n",
      "FPR: 0.8406535699235489\n",
      "TPR: 0.9547678394513863\n",
      "F-measure: 0.9379224882194964\n",
      "Precision: 0.9511902791098834\n",
      "Recall: 0.9547678394513863"
     ]
    }
   ],
   "source": [
    "#Classification Report for Logistic Regression \n",
    "\n",
    "# Load the Summary\n",
    "trainingSummary = LR_BestModel.summary\n",
    "\n",
    "# General Describe\n",
    "trainingSummary.predictions.describe().show()\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\" \")\n",
    "print(\"objectiveHistory: (scaled loss + regularization) at each iteration\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\" \")\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\" \")\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\" \")\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "# Generate confusion matrix and print (includes accuracy)\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\" \")\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13793d41-2c53-45af-8b80-f89048d857ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T23:56:52.159456Z",
     "iopub.status.busy": "2025-03-18T23:56:52.158989Z",
     "iopub.status.idle": "2025-03-18T23:56:52.294461Z",
     "shell.execute_reply": "2025-03-18T23:56:52.293073Z",
     "shell.execute_reply.started": "2025-03-18T23:56:52.159394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a326138a3dc64e628e6633fd4ebd7ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\nAccording to the Classification Report for Logisitic Regression, accuracy was at 95.48%, precision by label(\"isFradulent) for class 0 was at 95.55%, class 1 was at\\n87.08%, recall by label, for class 0 at 99.91% and class 1 at 11.44%. Overall precision at 95.11% and recall at 95.48%. This is a high accuracy rate, \\nI believe it may be better to increase the amount of folds in the future and preprocess the dataset more to look for any skewness and outliers. '"
     ]
    }
   ],
   "source": [
    "'''\n",
    "According to the Classification Report for Logisitic Regression, accuracy was at 95.48%, precision by label(\"isFradulent) for class 0 was at 95.55%, class 1 was at\n",
    "87.08%, recall by label, for class 0 at 99.91% and class 1 at 11.44%. Overall precision at 95.11% and recall at 95.48%. This is a high accuracy rate, \n",
    "I believe it may be better to increase the amount of folds in the future and preprocess the dataset more to look for any skewness and outliers. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca93f5d2-7dc6-4ce0-8ce1-87c82c4dbe69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T23:56:52.310626Z",
     "iopub.status.busy": "2025-03-18T23:56:52.307574Z",
     "iopub.status.idle": "2025-03-18T23:56:52.453225Z",
     "shell.execute_reply": "2025-03-18T23:56:52.452486Z",
     "shell.execute_reply.started": "2025-03-18T23:56:52.310585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f018bcd2bb64a97a2a4f2ab1d7cd1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in cell_monitor\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in <listcomp>\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "KeyError: 'jobGroup'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a67f6e49-c579-460c-a102-28bb2e139559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T23:56:52.461218Z",
     "iopub.status.busy": "2025-03-18T23:56:52.455577Z",
     "iopub.status.idle": "2025-03-19T00:00:58.541398Z",
     "shell.execute_reply": "2025-03-19T00:00:58.540671Z",
     "shell.execute_reply.started": "2025-03-18T23:56:52.461162Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8683b7d297314d64865b5c36171f47f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in cell_monitor\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in <listcomp>\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "KeyError: 'jobGroup'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in cell_monitor\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in <listcomp>\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "KeyError: 'jobGroup'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:  [4.60421360e-01 0.00000000e+00 6.51650084e-05 4.11730192e-01\n",
      " 1.27783283e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "Accuracy: 95.39%\n",
      "AUC DT: 0.5623"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "paramGrid = (ParamGridBuilder()                               \n",
    "             .addGrid(classifier.maxDepth, [5, 10, 20])  \n",
    "             .addGrid(classifier.maxBins, [10, 40])      \n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=3) # 3 + is best practice\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Collect and print feature importances\n",
    "BestModel = fitModel.bestModel\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "print(\"Feature Importances: \",featureImportances)\n",
    "\n",
    "#Decision Tree Identifer for ML Models \n",
    "DT_BestModel = BestModel\n",
    "\n",
    "predictions = fitModel.transform(test)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = MC_evaluator.evaluate(predictions) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Compute AUC for binary classification\n",
    "auc = Bin_evaluator.evaluate(predictions)\n",
    "print(f\"AUC DT: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae4ee26e-8ac3-43b4-a0d5-9c1e8ab7f081",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T00:00:58.545777Z",
     "iopub.status.busy": "2025-03-19T00:00:58.545557Z",
     "iopub.status.idle": "2025-03-19T00:01:23.921777Z",
     "shell.execute_reply": "2025-03-19T00:01:23.920894Z",
     "shell.execute_reply.started": "2025-03-19T00:00:58.545752Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5dfd0fee41641d886297291e37771e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in cell_monitor\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in <listcomp>\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "KeyError: 'jobGroup'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Evaluation\n",
      "Accuracy: 0.9539\n",
      "F1 Score: 0.9382\n",
      "Precision: 0.9448\n",
      "Recall: 0.9539"
     ]
    }
   ],
   "source": [
    "#Classification Report for Decision Tree\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Initialize evaluators\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(metricName=\"weightedPrecision\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(metricName=\"weightedRecall\")\n",
    "\n",
    "# Compute evaluation metrics for Decision Tree\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "f1_score = evaluator_f1.evaluate(predictions)\n",
    "precision = evaluator_precision.evaluate(predictions)\n",
    "recall = evaluator_recall.evaluate(predictions)\n",
    "\n",
    "# Print results\n",
    "print(\"Decision Tree Model Evaluation\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe947cf8-b0ad-444d-baab-4e93d3f4e1d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T00:01:23.924736Z",
     "iopub.status.busy": "2025-03-19T00:01:23.924471Z",
     "iopub.status.idle": "2025-03-19T00:01:24.025539Z",
     "shell.execute_reply": "2025-03-19T00:01:24.022530Z",
     "shell.execute_reply.started": "2025-03-19T00:01:23.924700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1834adcccdbb453ab040269a24d30e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\nAccording to our CLassification Report for Decision Tree, overall accuracy was at 95.43%, precision was at 94.67%, recall was at 95.43%. This result \\nshows a high accuracy which can be reduced if we did more preprocessing on the dataset, additionally we have have a lower accuracy if change our parameters \\nor cross val folds since this is a large dataset.'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "According to our CLassification Report for Decision Tree, overall accuracy was at 95.43%, precision was at 94.67%, recall was at 95.43%. This result \n",
    "shows a high accuracy which can be reduced if we did more preprocessing on the dataset, additionally we have have a lower accuracy if change our parameters \n",
    "or cross val folds since this is a large dataset.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8a4ac7e-8cb7-4ed7-9dbe-0f873b90ba56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T00:01:24.026749Z",
     "iopub.status.busy": "2025-03-19T00:01:24.026523Z",
     "iopub.status.idle": "2025-03-19T00:01:24.167318Z",
     "shell.execute_reply": "2025-03-19T00:01:24.166537Z",
     "shell.execute_reply.started": "2025-03-19T00:01:24.026715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf3117720414f78a18609cd1958856c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in cell_monitor\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in <listcomp>\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "KeyError: 'jobGroup'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Naive-Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24d9c456-4548-42cd-93cd-6b77334789f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T00:01:24.173122Z",
     "iopub.status.busy": "2025-03-19T00:01:24.172630Z",
     "iopub.status.idle": "2025-03-19T00:02:21.928647Z",
     "shell.execute_reply": "2025-03-19T00:02:21.927867Z",
     "shell.execute_reply.started": "2025-03-19T00:01:24.173069Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in cell_monitor\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in <listcomp>\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "KeyError: 'jobGroup'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c414d055f00d488795024e71e29cb0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in cell_monitor\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in <listcomp>\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "KeyError: 'jobGroup'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.99%\n",
      "AUC DT: 0.5000"
     ]
    }
   ],
   "source": [
    "# Add parameters of your choice here:\n",
    "classifier = NaiveBayes()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "             .addGrid(classifier.smoothing, [0.0, 0.2, 0.4, 0.6]) \\\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "#Naives-Bayes Identifer for ML Models \n",
    "NB_BestModel = BestModel\n",
    "\n",
    "predictions = fitModel.transform(test)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = MC_evaluator.evaluate(predictions) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Compute AUC for binary classification\n",
    "auc = Bin_evaluator.evaluate(predictions)\n",
    "print(f\"AUC DT: {auc:.4f}\") #AUC NB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33ab74d3-bd48-4578-b343-dc794fdacd0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T00:02:21.929739Z",
     "iopub.status.busy": "2025-03-19T00:02:21.929564Z",
     "iopub.status.idle": "2025-03-19T00:02:47.314211Z",
     "shell.execute_reply": "2025-03-19T00:02:47.313543Z",
     "shell.execute_reply.started": "2025-03-19T00:02:21.929715Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80396ea36cdf4ce9976132165e7b1280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in cell_monitor\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in <listcomp>\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "KeyError: 'jobGroup'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes Evaluation\n",
      "Accuracy: 0.9499\n",
      "F1 Score: 0.9254\n",
      "Precision: 0.9022\n",
      "Recall: 0.9499"
     ]
    }
   ],
   "source": [
    "#Classification Report for Naive-Bayes\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Initialize evaluators\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(metricName=\"weightedPrecision\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(metricName=\"weightedRecall\")\n",
    "\n",
    "# Compute evaluation metrics for Naive-Bayes\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "f1_score = evaluator_f1.evaluate(predictions)\n",
    "precision = evaluator_precision.evaluate(predictions)\n",
    "recall = evaluator_recall.evaluate(predictions)\n",
    "\n",
    "# Print results\n",
    "print(\"Naive-Bayes Evaluation\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1a98b1-8540-4136-8d7e-f606931c340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "According to our CLassification Report for Naive-Bayes, overall accuracy was at 94.99%, precision was at 90.22%, recall was at 94.99%. This result \n",
    "shows a high accuracy which can be reduced if we did more preprocessing on the dataset such as more binning and smoothing techniques. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615f86b-bc07-4a1a-b7c4-7a87e2fc3205",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Therefore, all models performed similarly with logistic regression with accuracy at 95.47%, decision tree with accuracy at 95.39%, and Naive-Bayes \n",
    "with accuracy at 94.99%.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
